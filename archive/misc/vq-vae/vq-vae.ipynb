{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import tqdm as tqdm\n",
    "import lightning.pytorch as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "\n",
    "class ResidualStack(nn.Module):\n",
    "    def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
    "        super().__init__()\n",
    "        # See Section 4.1 of \"Neural Discrete Representation Learning\".\n",
    "        layers = []\n",
    "        for i in range(num_residual_layers):\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=num_hiddens,\n",
    "                        out_channels=num_residual_hiddens,\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                    ),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=num_residual_hiddens,\n",
    "                        out_channels=num_hiddens,\n",
    "                        kernel_size=1,\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        for layer in self.layers:\n",
    "            h = h + layer(h)\n",
    "\n",
    "        # ResNet V1-style.\n",
    "        return torch.relu(h)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        num_hiddens,\n",
    "        num_downsampling_layers,\n",
    "        num_residual_layers,\n",
    "        num_residual_hiddens,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # See Section 4.1 of \"Neural Discrete Representation Learning\".\n",
    "        # The last ReLU from the Sonnet example is omitted because ResidualStack starts\n",
    "        # off with a ReLU.\n",
    "        conv = nn.Sequential()\n",
    "        for downsampling_layer in range(num_downsampling_layers):\n",
    "            if downsampling_layer == 0:\n",
    "                out_channels = num_hiddens // 2\n",
    "            elif downsampling_layer == 1:\n",
    "                (in_channels, out_channels) = (num_hiddens // 2, num_hiddens)\n",
    "\n",
    "            else:\n",
    "                (in_channels, out_channels) = (num_hiddens, num_hiddens)\n",
    "\n",
    "            conv.add_module(\n",
    "                f\"down{downsampling_layer}\",\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=4,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                ),\n",
    "            )\n",
    "            conv.add_module(f\"relu{downsampling_layer}\", nn.ReLU())\n",
    "\n",
    "        conv.add_module(\n",
    "            \"final_conv\",\n",
    "            nn.Conv2d(\n",
    "                in_channels=num_hiddens,\n",
    "                out_channels=num_hiddens,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "            ),\n",
    "        )\n",
    "        self.conv = conv\n",
    "        self.residual_stack = ResidualStack(\n",
    "            num_hiddens, num_residual_layers, num_residual_hiddens\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        return self.residual_stack(h)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim,\n",
    "        num_hiddens,\n",
    "        num_upsampling_layers,\n",
    "        num_residual_layers,\n",
    "        num_residual_hiddens,\n",
    "        out,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # See Section 4.1 of \"Neural Discrete Representation Learning\".\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=embedding_dim,\n",
    "            out_channels=num_hiddens,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.residual_stack = ResidualStack(\n",
    "            num_hiddens, num_residual_layers, num_residual_hiddens\n",
    "        )\n",
    "        upconv = nn.Sequential()\n",
    "        for upsampling_layer in range(num_upsampling_layers):\n",
    "            if upsampling_layer < num_upsampling_layers - 2:\n",
    "                (in_channels, out_channels) = (num_hiddens, num_hiddens)\n",
    "\n",
    "            elif upsampling_layer == num_upsampling_layers - 2:\n",
    "                (in_channels, out_channels) = (num_hiddens, num_hiddens // 2)\n",
    "\n",
    "            elif upsampling_layer > num_upsampling_layers - 2:\n",
    "                (in_channels, out_channels) = (num_hiddens // 2, out)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid upsampling layer: {upsampling_layer}. In Encoder.\"\n",
    "                )\n",
    "\n",
    "            upconv.add_module(\n",
    "                f\"up{upsampling_layer}\",\n",
    "                nn.ConvTranspose2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=4,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                ),\n",
    "            )\n",
    "            if upsampling_layer < num_upsampling_layers - 1:\n",
    "                upconv.add_module(f\"relu{upsampling_layer}\", nn.ReLU())\n",
    "\n",
    "        self.upconv = upconv\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = self.residual_stack(h)\n",
    "        x_recon = self.upconv(h)\n",
    "        return F.sigmoid(x_recon)\n",
    "\n",
    "\n",
    "class SonnetExponentialMovingAverage(nn.Module):\n",
    "    # See: https://github.com/deepmind/sonnet/blob/5cbfdc356962d9b6198d5b63f0826a80acfdf35b/sonnet/src/moving_averages.py#L25.\n",
    "    # They do *not* use the exponential moving average updates described in Appendix A.1\n",
    "    # of \"Neural Discrete Representation Learning\".\n",
    "    def __init__(self, decay, shape):\n",
    "        super().__init__()\n",
    "        self.decay = decay\n",
    "        self.counter = 0\n",
    "        self.register_buffer(\"hidden\", torch.zeros(*shape))\n",
    "        self.register_buffer(\"average\", torch.zeros(*shape))\n",
    "\n",
    "    def update(self, value):\n",
    "        self.counter += 1\n",
    "        with torch.no_grad():\n",
    "            self.hidden -= (self.hidden - value) * (1 - self.decay)\n",
    "            self.average = self.hidden / (1 - self.decay**self.counter)\n",
    "\n",
    "    def __call__(self, value):\n",
    "        self.update(value)\n",
    "        return self.average\n",
    "\n",
    "\n",
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_embeddings, use_ema, decay, epsilon):\n",
    "        super().__init__()\n",
    "        # See Section 3 of \"Neural Discrete Representation Learning\" and:\n",
    "        # https://github.com/deepmind/sonnet/blob/v2/sonnet/src/nets/vqvae.py#L142.\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.use_ema = use_ema\n",
    "        # Weight for the exponential moving average.\n",
    "        self.decay = decay\n",
    "        # Small constant to avoid numerical instability in embedding updates.\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # Dictionary embeddings.\n",
    "        limit = 3**0.5\n",
    "        e_i_ts = torch.FloatTensor(embedding_dim, num_embeddings).uniform_(\n",
    "            -limit, limit\n",
    "        )\n",
    "        if use_ema:\n",
    "            self.register_buffer(\"e_i_ts\", e_i_ts)\n",
    "        else:\n",
    "            self.register_parameter(\"e_i_ts\", nn.Parameter(e_i_ts))\n",
    "\n",
    "        # Exponential moving average of the cluster counts.\n",
    "        self.N_i_ts = SonnetExponentialMovingAverage(decay, (num_embeddings,))\n",
    "        # Exponential moving average of the embeddings.\n",
    "        self.m_i_ts = SonnetExponentialMovingAverage(decay, e_i_ts.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        flat_x = x.permute(0, 2, 3, 1).reshape(-1, self.embedding_dim)\n",
    "        distances = (\n",
    "            (flat_x**2).sum(1, keepdim=True)\n",
    "            - 2 * flat_x @ self.e_i_ts\n",
    "            + (self.e_i_ts**2).sum(0, keepdim=True)\n",
    "        )\n",
    "        encoding_indices = distances.argmin(1)\n",
    "        quantized_x = F.embedding(\n",
    "            encoding_indices.view(x.shape[0], *x.shape[2:]), self.e_i_ts.transpose(0, 1)\n",
    "        ).permute(0, 3, 1, 2)\n",
    "\n",
    "        # See second term of Equation (3).\n",
    "        if not self.use_ema:\n",
    "            dictionary_loss = ((x.detach() - quantized_x) ** 2).mean()\n",
    "        else:\n",
    "            dictionary_loss = None\n",
    "\n",
    "        # See third term of Equation (3).\n",
    "        commitment_loss = ((x - quantized_x.detach()) ** 2).mean()\n",
    "        # Straight-through gradient. See Section 3.2.\n",
    "        quantized_x = x + (quantized_x - x).detach()\n",
    "\n",
    "        if self.use_ema and self.training:\n",
    "            with torch.no_grad():\n",
    "                # See Appendix A.1 of \"Neural Discrete Representation Learning\".\n",
    "\n",
    "                # Cluster counts.\n",
    "                encoding_one_hots = F.one_hot(\n",
    "                    encoding_indices, self.num_embeddings\n",
    "                ).type(flat_x.dtype)\n",
    "                n_i_ts = encoding_one_hots.sum(0)\n",
    "                # Updated exponential moving average of the cluster counts.\n",
    "                # See Equation (6).\n",
    "                self.N_i_ts(n_i_ts)\n",
    "\n",
    "                # Exponential moving average of the embeddings. See Equation (7).\n",
    "                embed_sums = flat_x.transpose(0, 1) @ encoding_one_hots\n",
    "                self.m_i_ts(embed_sums)\n",
    "\n",
    "                # This is kind of weird.\n",
    "                # Compare: https://github.com/deepmind/sonnet/blob/v2/sonnet/src/nets/vqvae.py#L270\n",
    "                # and Equation (8).\n",
    "                N_i_ts_sum = self.N_i_ts.average.sum()\n",
    "                N_i_ts_stable = (\n",
    "                    (self.N_i_ts.average + self.epsilon)\n",
    "                    / (N_i_ts_sum + self.num_embeddings * self.epsilon)\n",
    "                    * N_i_ts_sum\n",
    "                )\n",
    "                self.e_i_ts = self.m_i_ts.average / N_i_ts_stable.unsqueeze(0)\n",
    "\n",
    "        return (\n",
    "            quantized_x,\n",
    "            dictionary_loss,\n",
    "            commitment_loss,\n",
    "            encoding_indices.view(x.shape[0], -1),\n",
    "        )\n",
    "\n",
    "\n",
    "class VQVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        num_hiddens,\n",
    "        num_downsampling_layers,\n",
    "        num_residual_layers,\n",
    "        num_residual_hiddens,\n",
    "        embedding_dim,\n",
    "        num_embeddings,\n",
    "        use_ema,\n",
    "        decay,\n",
    "        epsilon,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(\n",
    "            in_channels,\n",
    "            num_hiddens,\n",
    "            num_downsampling_layers,\n",
    "            num_residual_layers,\n",
    "            num_residual_hiddens,\n",
    "        )\n",
    "        self.pre_vq_conv = nn.Conv2d(\n",
    "            in_channels=num_hiddens, out_channels=embedding_dim, kernel_size=1\n",
    "        )\n",
    "        self.vq = VectorQuantizer(\n",
    "            embedding_dim, num_embeddings, use_ema, decay, epsilon\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            embedding_dim,\n",
    "            num_hiddens,\n",
    "            num_downsampling_layers,\n",
    "            num_residual_layers,\n",
    "            num_residual_hiddens,\n",
    "            out_channels,\n",
    "        )\n",
    "\n",
    "    def quantize(self, x):\n",
    "        z = self.pre_vq_conv(self.encoder(x))\n",
    "        (z_quantized, dictionary_loss, commitment_loss, encoding_indices) = self.vq(z)\n",
    "        return (z_quantized, dictionary_loss, commitment_loss, encoding_indices)\n",
    "\n",
    "    def forward(self, x):\n",
    "        (z_quantized, dictionary_loss, commitment_loss, encoding_indices) = (\n",
    "            self.quantize(x)\n",
    "        )\n",
    "        x_recon = self.decoder(z_quantized)\n",
    "        return {\n",
    "            \"dictionary_loss\": dictionary_loss,\n",
    "            \"commitment_loss\": commitment_loss,\n",
    "            \"x_recon\": x_recon,\n",
    "            \"encoding_indices\": encoding_indices,\n",
    "        }\n",
    "\n",
    "\n",
    "class VQVAE_Trainer(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_size=64,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        num_hiddens=64,\n",
    "        num_downsampling_layers=2,\n",
    "        num_residual_layers=2,\n",
    "        num_residual_hiddens=128,\n",
    "        embedding_dim=4,  # 32, 64, 128, 256\n",
    "        num_embeddings=64,  # 256, 512, 1024, 2048\n",
    "        use_ema=True,\n",
    "        decay=0.99,\n",
    "        epsilon=1e-5,\n",
    "        beta=0.25,\n",
    "        lr=2e-4,\n",
    "        weight_decay=0.0,\n",
    "        fid_features=2048,\n",
    "        batch_size=64,  # 128\n",
    "        dataset=\"celeba_hq\",\n",
    "    ):\n",
    "        super(VQVAE_Trainer, self).__init__()\n",
    "        self.model = VQVAE(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            num_hiddens=num_hiddens,\n",
    "            num_downsampling_layers=num_downsampling_layers,\n",
    "            num_residual_layers=num_residual_layers,\n",
    "            num_residual_hiddens=num_residual_hiddens,\n",
    "            embedding_dim=embedding_dim,\n",
    "            num_embeddings=num_embeddings,\n",
    "            use_ema=use_ema,\n",
    "            decay=decay,\n",
    "            epsilon=epsilon,\n",
    "        )\n",
    "\n",
    "        self.beta = beta\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        out = self.model(x)\n",
    "        recon_error = F.mse_loss(out[\"x_recon\"], x)\n",
    "\n",
    "        loss = recon_error + self.beta * out[\"commitment_loss\"]\n",
    "\n",
    "        if out[\"dictionary_loss\"] is not None:\n",
    "            loss += out[\"dictionary_loss\"]\n",
    "            self.log(\"train_dictionary_loss\", out[\"dictionary_loss\"])\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_recon_error\", recon_error)\n",
    "        self.log(\"train_commitment_loss\", out[\"commitment_loss\"])\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        out = self.model(x)\n",
    "\n",
    "        recon_error = F.mse_loss(out[\"x_recon\"], x)\n",
    "\n",
    "        loss = recon_error + self.beta * out[\"commitment_loss\"]\n",
    "\n",
    "        if out[\"dictionary_loss\"] is not None:\n",
    "            loss += out[\"dictionary_loss\"]\n",
    "            self.log(\"val_dictionary_loss\", out[\"dictionary_loss\"])\n",
    "\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_recon_error\", recon_error)\n",
    "        self.log(\"val_commitment_loss\", out[\"commitment_loss\"])\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            if self.global_step == 0 and batch_idx == 0:\n",
    "                self.logger.experiment.log(\n",
    "                    {\n",
    "                        \"original\": wandb.Image(\n",
    "                            torchvision.utils.make_grid(x[:64], nrow=8),\n",
    "                            caption=\"Real Image\",\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            self.logger.experiment.log(\n",
    "                {\n",
    "                    \"reconstructed\": wandb.Image(\n",
    "                        torchvision.utils.make_grid(out[\"x_recon\"][:64], nrow=8),\n",
    "                        caption=f\"Step {self.global_step}\",\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "    def on_test_start(self):\n",
    "        self.fid = FrechetInceptionDistance(self.hparams.fid_features).cpu()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        out = self.model(x)\n",
    "\n",
    "        # Resize to 299x299\n",
    "        x = F.interpolate(x, size=299)\n",
    "        x_hat = F.interpolate(out[\"x_recon\"], size=299)\n",
    "\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "            x_hat = x_hat.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # Convert to uint8\n",
    "        x = (x * 255).to(torch.uint8).cpu()\n",
    "        x_hat = (x_hat * 255).to(torch.uint8).cpu()\n",
    "\n",
    "        # Compute FID\n",
    "        self.fid.update(x, real=True)\n",
    "        self.fid.update(x_hat, real=False)\n",
    "\n",
    "        fid_score = self.fid.compute()\n",
    "        self.log(\"fid_score\", fid_score)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            amsgrad=True,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.hparams.dataset == \"mnist\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    (\n",
    "                        torchvision.transforms.Grayscale()\n",
    "                        if self.hparams.in_channels == 1\n",
    "                        else torchvision.transforms.Lambda(lambda x: x)\n",
    "                    ),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.MNIST(\n",
    "                root=\"data/mnist\", train=True, transform=transform, download=True\n",
    "            )\n",
    "\n",
    "        elif self.hparams.dataset == \"cifar10\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.CIFAR10(\n",
    "                root=\"data/cifar10\", train=True, transform=transform, download=True\n",
    "            )\n",
    "\n",
    "        elif self.hparams.dataset == \"celeba_hq\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.ImageFolder(\n",
    "                \"data/celeba_hq/train\", transform=transform\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset: {self.hparams.dataset}\")\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        if self.hparams.dataset == \"mnist\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.MNIST(\n",
    "                root=\"data/mnist\", train=False, transform=transform, download=True\n",
    "            )\n",
    "\n",
    "        elif self.hparams.dataset == \"cifar10\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.CIFAR10(\n",
    "                root=\"data/cifar10\", train=False, transform=transform, download=True\n",
    "            )\n",
    "\n",
    "        elif self.hparams.dataset == \"celeba_hq\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.ImageFolder(\n",
    "                \"data/celeba_hq/val\", transform=transform\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset: {self.hparams.dataset}\")\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        if self.hparams.dataset == \"mnist\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.MNIST(\n",
    "                root=\"data/mnist\", train=False, transform=transform, download=True\n",
    "            )\n",
    "            # Return first 1/4\n",
    "            dataset = torch.utils.data.Subset(dataset, range(len(dataset) // 16))\n",
    "\n",
    "        elif self.hparams.dataset == \"cifar10\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.CIFAR10(\n",
    "                root=\"data/cifar10\", train=False, transform=transform, download=True\n",
    "            )\n",
    "            # Return first 1/4\n",
    "            dataset = torch.utils.data.Subset(dataset, range(len(dataset) // 16))\n",
    "\n",
    "        elif self.hparams.dataset == \"celeba_hq\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.ImageFolder(\n",
    "                \"data/celeba_hq/val\", transform=transform\n",
    "            )\n",
    "            # Return first 1/4\n",
    "            dataset = torch.utils.data.Subset(dataset, range(len(dataset) // 4))\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset: {self.hparams.dataset}\")\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae = VQVAE_Trainer.load_from_checkpoint(\"vqvae/logs/vq-vae/o8cxx8bp/checkpoints/epoch=9-step=9380.ckpt\")\n",
    "model = vqvae.model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16])\n"
     ]
    }
   ],
   "source": [
    "# Print codebookshape\n",
    "print(model.vq.e_i_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = vqvae.train_dataloader()\n",
    "val_loader = vqvae.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 170.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n",
      "torch.Size([60000, 64])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    classes = []\n",
    "    idxs = []\n",
    "\n",
    "    for x, y in tqdm.tqdm(train_loader):    \n",
    "        x = x.to(\"mps\")\n",
    "\n",
    "        out = model.quantize(x)[3]\n",
    "        \n",
    "        classes.extend(y.tolist())\n",
    "        idxs.extend(out.tolist())\n",
    "        \n",
    "    classes = torch.tensor(classes)\n",
    "    idxs = torch.tensor(idxs)\n",
    "\n",
    "    print(classes.shape)\n",
    "    print(idxs.shape)\n",
    "\n",
    "    # Convert to int dataset and save\n",
    "    dataset = torch.utils.data.TensorDataset(idxs, classes)\n",
    "    # torch.save(dataset, \"projects/custom/vq-vae/train_z_embed.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train\n",
    "# Plot distribution of indices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = torch.bincount(idxs.flatten())\n",
    "plt.bar(range(len(counts)), counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train\n",
    "# Plot distribution of indices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = torch.bincount(idxs.flatten())\n",
    "plt.bar(range(len(counts)), counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 186.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n",
      "torch.Size([10000, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    classes = []\n",
    "    idxs = []\n",
    "\n",
    "    for x, y in tqdm.tqdm(val_loader):    \n",
    "        x = x.to(\"mps\")\n",
    "\n",
    "        out = model.quantize(x)[3]\n",
    "        \n",
    "        classes.extend(y.tolist())\n",
    "        idxs.extend(out.tolist())\n",
    "        \n",
    "    classes = torch.tensor(classes)\n",
    "    idxs = torch.tensor(idxs)\n",
    "\n",
    "    print(classes.shape)\n",
    "    print(idxs.shape)\n",
    "\n",
    "    # Convert to int dataset and save\n",
    "    dataset = torch.utils.data.TensorDataset(idxs, classes)\n",
    "    # torch.save(dataset, \"projects/custom/vq-vae/val_z_embed.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# val\n",
    "# Plot distribution of indices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = torch.bincount(idxs.flatten())\n",
    "plt.bar(range(len(counts)), counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.load(\"projects/custom/vq-vae/train_indexed.pt\"),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "# Val Loader\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    torch.load(\"projects/custom/vq-vae/val_indexed.pt\"),\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # Replace LSTM with GRU\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to predict each character\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # Embedding\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Initialize hidden state if not provided\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(self.num_layers, x.size(0), self.hidden_dim, device=x.device)\n",
    "        \n",
    "        # GRU output along with new hidden state\n",
    "        out, hidden = self.gru(x, hidden)\n",
    "        \n",
    "        # Reshape output for the fully connected layer\n",
    "        out = out.reshape(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "# Create an instance of the updated model\n",
    "vocab_size = 2048  # number of unique characters\n",
    "embed_dim = 128   # embedding dimension\n",
    "hidden_dim = 256  # LSTM hidden dimensions\n",
    "num_layers = 4  # number of GRU layers\n",
    "\n",
    "lstm = Model(vocab_size, embed_dim, hidden_dim, num_layers).to(\"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(lstm, input_data=torch.zeros((64, 64), dtype=torch.long).to(\"mps\"), depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(lstm.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def decode_idxs(idxs):\n",
    "    print(idxs.shape)\n",
    "    quantized_x = F.embedding(\n",
    "        idxs.view(1, 32, 32), model.vq.e_i_ts.transpose(0, 1)\n",
    "    ).permute(0, 3, 1, 2)\n",
    "    print(quantized_x.shape)\n",
    "    # reconstruct\n",
    "    x_recon = model.decoder(quantized_x)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(torchvision.utils.make_grid(x_recon[:64], nrow=8).cpu().numpy().transpose(1, 2, 0))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def temperature_sampling(logits, temperature=0.7):\n",
    "    # Scale logits by temperature\n",
    "    scaled_logits = logits / temperature\n",
    "    # Convert logits to probabilities\n",
    "    probs = F.softmax(scaled_logits, dim=-1)\n",
    "    # Sample from the probabilities\n",
    "    return torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "def generate(len=1024, temperature=0.8):\n",
    "    # Validation Loop with Temperature Sampling\n",
    "    lstm.eval()\n",
    "    initial_input = torch.randint(0, vocab_size, (1, 1), dtype=torch.long).to(\"mps\")\n",
    "    generated_text = []\n",
    "    hidden = None  # Hidden state initialization\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(len):  # Generate 64 characters\n",
    "            output, hidden = lstm(initial_input, hidden)  # Ensure model accepts and returns hidden state\n",
    "            predicted = temperature_sampling(output[-1], temperature=temperature)\n",
    "            generated_text.append(predicted)\n",
    "            initial_input = predicted.unsqueeze(0)\n",
    "\n",
    "    generated = torch.stack(generated_text).squeeze()\n",
    "\n",
    "    decode_idxs(generated)\n",
    "\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   7%|▋         | 29/438 [07:05<1:39:58, 14.67s/it, Loss: 6.1464]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)  \u001b[38;5;66;03m# Loss calculation between outputs and shifted targets\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Coding/repos/ml-zoo/venv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/repos/ml-zoo/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(train_loader) as pbar:\n",
    "        for x, y in pbar:\n",
    "            x = x.to(\"mps\")\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Encode sequence and prepare inputs and targets\n",
    "            inputs = x[:, :-1]  # All characters except the last\n",
    "            targets = x[:, 1:].flatten()  # All characters except the first, flattened for loss calculation\n",
    "\n",
    "            # Forward pass\n",
    "            outputs, _ = lstm(inputs)  # Outputs now includes hidden states which are ignored during training\n",
    "            loss = criterion(outputs, targets)  # Loss calculation between outputs and shifted targets\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix_str(f\"Loss: {loss.item():.4f}\")\n",
    "            pbar.set_description(f\"Epoch {epoch + 1}/{epochs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
