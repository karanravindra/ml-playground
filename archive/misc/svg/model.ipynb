{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers.processors\n",
    "\n",
    "\n",
    "tokenizer = tokenizers.Tokenizer.from_file(\"data/icons/vocab/tokenizer.json\")\n",
    "tokenizer.post_processor = tokenizers.processors.TemplateProcessing(\n",
    "    single=\"<SOS> $A <EOS>\",\n",
    "    special_tokens=[(\"<SOS>\", 0), (\"<EOS>\", 1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(tokenizer.get_vocab(), key=lambda x: tokenizer.get_vocab()[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Dataloader:\n",
    "    def __init__(self, use_train: bool):\n",
    "        self.root = \"data/icons/outline/\" + (\"train\" if use_train else \"test\")\n",
    "        self.files = os.listdir(self.root)\n",
    "        self.use_train = use_train\n",
    "        self.max_size = 0\n",
    "        self.file = None\n",
    "        self._make_corpus(file=\"data/icons/outline/train-corpus.txt\" if use_train else \"data/icons/outline/test-corpus.txt\")\n",
    "        self.corpus = self._load_corpus(file=\"data/icons/outline/train-corpus.txt\" if use_train else \"data/icons/outline/test-corpus.txt\")\n",
    "        print(\"Max Size\", self.max_size)\n",
    "        print(\"Files\", self.file)\n",
    "\n",
    "    def _make_corpus (self, file=\"data/icons/outline/train-corpus.txt\"):\n",
    "        with open(file, \"w\") as f:\n",
    "            for file in self.files:\n",
    "                with open(self.root + \"/\" + file) as g:\n",
    "                    encoded = tokenizer.encode(g.read()).ids\n",
    "                    self.max_size = max(self.max_size, len(encoded))\n",
    "                    self.file = file\n",
    "                    f.write(\" \".join(map(str, encoded)) + \" \")\n",
    "    \n",
    "    def _load_corpus(self, file=\"data/icons/outline/train-corpus.txt\"):\n",
    "        with open(file) as f:\n",
    "            return list(map(int, f.read().split()))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.corpus) - 1\n",
    "    \n",
    "    def get_batch(self, batch_size: int, seq_len: int):\n",
    "        idx = torch.randint(0, len(self.corpus) - seq_len, (batch_size,))\n",
    "\n",
    "        return torch.stack([torch.tensor(self.corpus[i:i+seq_len]) for i in idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Dataloader(True)\n",
    "test_loader = Dataloader(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.token_to_id(\"[SOS]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "config = transformers.LlamaConfig(\n",
    "    vocab_size=128,\n",
    "    hidden_size=64,\n",
    "    intermediate_size=128,\n",
    "    num_hidden_layers=8,\n",
    "    num_attention_heads=8,\n",
    "    max_position_embeddings=256,\n",
    "    attention_dropout=0,\n",
    "    pad_token_id=tokenizer.token_to_id(\"<PAD>\"),\n",
    "    bos_token_id=tokenizer.token_to_id(\"<SOS>\"),\n",
    "    eos_token_id=tokenizer.token_to_id(\"<EOS>\"),\n",
    ")\n",
    "model = transformers.LlamaForCausalLM(config).to(device)\n",
    "num_train_steps = 0\n",
    "print(f\"Model using {model.num_parameters():,} parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    batch = test_loader.get_batch(64, 256).to(device)\n",
    "    x = batch[:,:-1]\n",
    "    y = batch[:,1:]\n",
    "\n",
    "    output = model(x, labels=y)\n",
    "\n",
    "    loss = output.loss\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = train_loader.get_batch(1, 256)\n",
    "b[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_f(x):\n",
    "    print(tokenizer.decode(x[0].tolist()).replace(\"   \", \" \\t\").replace(\" \", \"\").replace(\"\\t\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_pytorch import EMA\n",
    "ema = EMA(model, beta=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm.trange(10_000)\n",
    "for step in pbar:\n",
    "    model.train()\n",
    "    # Encode the sequence\n",
    "    batch = train_loader.get_batch(64, 256).to(device)\n",
    "    x = batch[:,:-1]\n",
    "    y = batch[:,1:]\n",
    "        \n",
    "    # Forward pass\n",
    "    output = model(x, labels=y)\n",
    "    loss = output.loss\n",
    "        \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # scheduler.step()\n",
    "\n",
    "    ema.update()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        val_loss = evaluate()\n",
    "        \n",
    "    pbar.set_postfix_str(f\"Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    idxs = model.generate(torch.tensor([[1]]).to(device), max_length=256)\n",
    "    print(idxs.flatten().tolist())\n",
    "    decode_f(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
