{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_files = \"data/tiny-stories/train.txt\"\n",
    "val_files = \"data/tiny-stories/validation.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_files, \"r\") as f:\n",
    "    train = f.read()\n",
    "\n",
    "with open(val_files, \"r\") as f:\n",
    "    val = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "from tokenizers.tools import EncodingVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tokenizers.models.BPE()\n",
    "trainer = tokenizers.trainers.BpeTrainer(vocab_size=256, special_tokens=[\"[PAD]\", \"[SOS]\", \"[EOS]\", \"[MASK]\", \"[UNK]\"], show_progress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizers.Tokenizer(model=model)\n",
    "tokenizer.pre_tokenizer = tokenizers.pre_tokenizers.Sequence(\n",
    "    [tokenizers.pre_tokenizers.Digits(True)]\n",
    ")\n",
    "\n",
    "# tokenizer.add_tokens(\n",
    "#     *[\n",
    "#         [tokenizers.AddedToken(chr(i)) for i in range(32, 127)]\n",
    "#         + [\n",
    "#             tokenizers.AddedToken(\n",
    "#                 '''\n",
    "#   <path d=\"'''\n",
    "#             ),\n",
    "#             tokenizers.AddedToken('\" />'),\n",
    "#             tokenizers.AddedToken('\\n'),\n",
    "#             tokenizers.AddedToken('''\n",
    "# <svg\n",
    "#   xmlns=\"http://www.w3.org/2000/svg\"\n",
    "#   width=\"24\"\n",
    "#   height=\"24\"\n",
    "#   viewBox=\"0 0 24 24\"\n",
    "#   fill=\"none\"\n",
    "#   stroke=\"currentColor\"\n",
    "#   stroke-width=\"2\"\n",
    "#   stroke-linecap=\"round\"\n",
    "#   stroke-linejoin=\"round\"\n",
    "# >'''),\n",
    "#             tokenizers.AddedToken('</svg>'),\n",
    "#         ]\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "tokenizer.train([train_files], trainer=trainer)\n",
    "print(tokenizer.get_vocab_size())\n",
    "\n",
    "print(tokenizer.encode(\"asdfasdfasdf\").tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = EncodingVisualizer(tokenizer)\n",
    "viz(train[0:1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(val[0:1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(train[:1_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoded.ids\n",
    "# most frequent ids\n",
    "frequency = {\n",
    "    tokenizer.decode([i]): encoded.count(i)\n",
    "    for i in sorted(set(encoded), key=lambda x: encoded.count(x), reverse=False)\n",
    "}\n",
    "\n",
    "print(frequency)\n",
    "print(len(frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(frequency.keys(), frequency.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"data/icons/vocab/tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
