{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VQ-VAE implementation in PyTorch.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import tqdm as tqdm\n",
    "import lightning.pytorch as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "\n",
    "class ResidualStack(nn.Module):\n",
    "    def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
    "        super().__init__()\n",
    "        # See Section 4.1 of \"Neural Discrete Representation Learning\".\n",
    "        layers = []\n",
    "        for i in range(num_residual_layers):\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=num_hiddens,\n",
    "                        out_channels=num_residual_hiddens,\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                    ),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=num_residual_hiddens,\n",
    "                        out_channels=num_hiddens,\n",
    "                        kernel_size=1,\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        for layer in self.layers:\n",
    "            h = h + layer(h)\n",
    "\n",
    "        # ResNet V1-style.\n",
    "        return torch.relu(h)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        num_hiddens,\n",
    "        num_downsampling_layers,\n",
    "        num_residual_layers,\n",
    "        num_residual_hiddens,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # See Section 4.1 of \"Neural Discrete Representation Learning\".\n",
    "        # The last ReLU from the Sonnet example is omitted because ResidualStack starts\n",
    "        # off with a ReLU.\n",
    "        conv = nn.Sequential()\n",
    "        for downsampling_layer in range(num_downsampling_layers):\n",
    "            if downsampling_layer == 0:\n",
    "                out_channels = num_hiddens // 2\n",
    "            elif downsampling_layer == 1:\n",
    "                (in_channels, out_channels) = (num_hiddens // 2, num_hiddens)\n",
    "\n",
    "            else:\n",
    "                (in_channels, out_channels) = (num_hiddens, num_hiddens)\n",
    "\n",
    "            conv.add_module(\n",
    "                f\"down{downsampling_layer}\",\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=4,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                ),\n",
    "            )\n",
    "            conv.add_module(f\"relu{downsampling_layer}\", nn.ReLU())\n",
    "\n",
    "        conv.add_module(\n",
    "            \"final_conv\",\n",
    "            nn.Conv2d(\n",
    "                in_channels=num_hiddens,\n",
    "                out_channels=num_hiddens,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "            ),\n",
    "        )\n",
    "        self.conv = conv\n",
    "        self.residual_stack = ResidualStack(\n",
    "            num_hiddens, num_residual_layers, num_residual_hiddens\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        return self.residual_stack(h)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim,\n",
    "        num_hiddens,\n",
    "        num_upsampling_layers,\n",
    "        num_residual_layers,\n",
    "        num_residual_hiddens,\n",
    "        out,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # See Section 4.1 of \"Neural Discrete Representation Learning\".\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=embedding_dim,\n",
    "            out_channels=num_hiddens,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.residual_stack = ResidualStack(\n",
    "            num_hiddens, num_residual_layers, num_residual_hiddens\n",
    "        )\n",
    "        upconv = nn.Sequential()\n",
    "        for upsampling_layer in range(num_upsampling_layers):\n",
    "            if upsampling_layer < num_upsampling_layers - 2:\n",
    "                (in_channels, out_channels) = (num_hiddens, num_hiddens)\n",
    "\n",
    "            elif upsampling_layer == num_upsampling_layers - 2:\n",
    "                (in_channels, out_channels) = (num_hiddens, num_hiddens // 2)\n",
    "\n",
    "            elif upsampling_layer > num_upsampling_layers - 2:\n",
    "                (in_channels, out_channels) = (num_hiddens // 2, out)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid upsampling layer: {upsampling_layer}. In Encoder.\"\n",
    "                )\n",
    "\n",
    "            upconv.add_module(\n",
    "                f\"up{upsampling_layer}\",\n",
    "                nn.ConvTranspose2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=4,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                ),\n",
    "            )\n",
    "            if upsampling_layer < num_upsampling_layers - 1:\n",
    "                upconv.add_module(f\"relu{upsampling_layer}\", nn.ReLU())\n",
    "\n",
    "        self.upconv = upconv\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = self.residual_stack(h)\n",
    "        x_recon = self.upconv(h)\n",
    "        return F.sigmoid(x_recon)\n",
    "\n",
    "\n",
    "class SonnetExponentialMovingAverage(nn.Module):\n",
    "    # See: https://github.com/deepmind/sonnet/blob/5cbfdc356962d9b6198d5b63f0826a80acfdf35b/sonnet/src/moving_averages.py#L25.\n",
    "    # They do *not* use the exponential moving average updates described in Appendix A.1\n",
    "    # of \"Neural Discrete Representation Learning\".\n",
    "    def __init__(self, decay, shape):\n",
    "        super().__init__()\n",
    "        self.decay = decay\n",
    "        self.counter = 0\n",
    "        self.register_buffer(\"hidden\", torch.zeros(*shape))\n",
    "        self.register_buffer(\"average\", torch.zeros(*shape))\n",
    "\n",
    "    def update(self, value):\n",
    "        self.counter += 1\n",
    "        with torch.no_grad():\n",
    "            self.hidden -= (self.hidden - value) * (1 - self.decay)\n",
    "            self.average = self.hidden / (1 - self.decay**self.counter)\n",
    "\n",
    "    def __call__(self, value):\n",
    "        self.update(value)\n",
    "        return self.average\n",
    "\n",
    "\n",
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_embeddings, use_ema, decay, epsilon):\n",
    "        super().__init__()\n",
    "        # See Section 3 of \"Neural Discrete Representation Learning\" and:\n",
    "        # https://github.com/deepmind/sonnet/blob/v2/sonnet/src/nets/vqvae.py#L142.\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.use_ema = use_ema\n",
    "        # Weight for the exponential moving average.\n",
    "        self.decay = decay\n",
    "        # Small constant to avoid numerical instability in embedding updates.\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # Dictionary embeddings.\n",
    "        limit = 3**0.5\n",
    "        e_i_ts = torch.FloatTensor(embedding_dim, num_embeddings).uniform_(\n",
    "            -limit, limit\n",
    "        )\n",
    "        if use_ema:\n",
    "            self.register_buffer(\"e_i_ts\", e_i_ts)\n",
    "        else:\n",
    "            self.register_parameter(\"e_i_ts\", nn.Parameter(e_i_ts))\n",
    "\n",
    "        # Exponential moving average of the cluster counts.\n",
    "        self.N_i_ts = SonnetExponentialMovingAverage(decay, (num_embeddings,))\n",
    "        # Exponential moving average of the embeddings.\n",
    "        self.m_i_ts = SonnetExponentialMovingAverage(decay, e_i_ts.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        flat_x = x.permute(0, 2, 3, 1).reshape(-1, self.embedding_dim)\n",
    "        distances = (\n",
    "            (flat_x**2).sum(1, keepdim=True)\n",
    "            - 2 * flat_x @ self.e_i_ts\n",
    "            + (self.e_i_ts**2).sum(0, keepdim=True)\n",
    "        )\n",
    "        encoding_indices = distances.argmin(1)\n",
    "        quantized_x = F.embedding(\n",
    "            encoding_indices.view(x.shape[0], *x.shape[2:]), self.e_i_ts.transpose(0, 1)\n",
    "        ).permute(0, 3, 1, 2)\n",
    "\n",
    "        # See second term of Equation (3).\n",
    "        if not self.use_ema:\n",
    "            dictionary_loss = ((x.detach() - quantized_x) ** 2).mean()\n",
    "        else:\n",
    "            dictionary_loss = None\n",
    "\n",
    "        # See third term of Equation (3).\n",
    "        commitment_loss = ((x - quantized_x.detach()) ** 2).mean()\n",
    "        # Straight-through gradient. See Section 3.2.\n",
    "        quantized_x = x + (quantized_x - x).detach()\n",
    "\n",
    "        if self.use_ema and self.training:\n",
    "            with torch.no_grad():\n",
    "                # See Appendix A.1 of \"Neural Discrete Representation Learning\".\n",
    "\n",
    "                # Cluster counts.\n",
    "                encoding_one_hots = F.one_hot(\n",
    "                    encoding_indices, self.num_embeddings\n",
    "                ).type(flat_x.dtype)\n",
    "                n_i_ts = encoding_one_hots.sum(0)\n",
    "                # Updated exponential moving average of the cluster counts.\n",
    "                # See Equation (6).\n",
    "                self.N_i_ts(n_i_ts)\n",
    "\n",
    "                # Exponential moving average of the embeddings. See Equation (7).\n",
    "                embed_sums = flat_x.transpose(0, 1) @ encoding_one_hots\n",
    "                self.m_i_ts(embed_sums)\n",
    "\n",
    "                # This is kind of weird.\n",
    "                # Compare: https://github.com/deepmind/sonnet/blob/v2/sonnet/src/nets/vqvae.py#L270\n",
    "                # and Equation (8).\n",
    "                N_i_ts_sum = self.N_i_ts.average.sum()\n",
    "                N_i_ts_stable = (\n",
    "                    (self.N_i_ts.average + self.epsilon)\n",
    "                    / (N_i_ts_sum + self.num_embeddings * self.epsilon)\n",
    "                    * N_i_ts_sum\n",
    "                )\n",
    "                self.e_i_ts = self.m_i_ts.average / N_i_ts_stable.unsqueeze(0)\n",
    "\n",
    "        return (\n",
    "            quantized_x,\n",
    "            dictionary_loss,\n",
    "            commitment_loss,\n",
    "            encoding_indices.view(x.shape[0], -1),\n",
    "        )\n",
    "\n",
    "\n",
    "class VQVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        num_hiddens,\n",
    "        num_downsampling_layers,\n",
    "        num_residual_layers,\n",
    "        num_residual_hiddens,\n",
    "        embedding_dim,\n",
    "        num_embeddings,\n",
    "        use_ema,\n",
    "        decay,\n",
    "        epsilon,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(\n",
    "            in_channels,\n",
    "            num_hiddens,\n",
    "            num_downsampling_layers,\n",
    "            num_residual_layers,\n",
    "            num_residual_hiddens,\n",
    "        )\n",
    "        self.pre_vq_conv = nn.Conv2d(\n",
    "            in_channels=num_hiddens, out_channels=embedding_dim, kernel_size=1\n",
    "        )\n",
    "        self.vq = VectorQuantizer(\n",
    "            embedding_dim, num_embeddings, use_ema, decay, epsilon\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            embedding_dim,\n",
    "            num_hiddens,\n",
    "            num_downsampling_layers,\n",
    "            num_residual_layers,\n",
    "            num_residual_hiddens,\n",
    "            out_channels,\n",
    "        )\n",
    "\n",
    "    def quantize(self, x):\n",
    "        z = self.pre_vq_conv(self.encoder(x))\n",
    "        (z_quantized, dictionary_loss, commitment_loss, encoding_indices) = self.vq(z)\n",
    "        return (z_quantized, dictionary_loss, commitment_loss, encoding_indices)\n",
    "\n",
    "    def forward(self, x):\n",
    "        (z_quantized, dictionary_loss, commitment_loss, encoding_indices) = (\n",
    "            self.quantize(x)\n",
    "        )\n",
    "        x_recon = self.decoder(z_quantized)\n",
    "        return {\n",
    "            \"dictionary_loss\": dictionary_loss,\n",
    "            \"commitment_loss\": commitment_loss,\n",
    "            \"x_recon\": x_recon,\n",
    "            \"encoding_indices\": encoding_indices,\n",
    "        }\n",
    "\n",
    "\n",
    "class VQVAE_Trainer(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_size=128,\n",
    "        in_channels=3,\n",
    "        out_channels=3,\n",
    "        num_hiddens=64,\n",
    "        num_downsampling_layers=2,\n",
    "        num_residual_layers=4,\n",
    "        num_residual_hiddens=128,\n",
    "        embedding_dim=64,  # 32, 64, 128, 256\n",
    "        num_embeddings=2048,  # 256, 512, 1024, 2048\n",
    "        use_ema=True,\n",
    "        decay=0.99,\n",
    "        epsilon=1e-5,\n",
    "        beta=0.25,\n",
    "        lr=2e-4,\n",
    "        weight_decay=0.0,\n",
    "        fid_features=2048,\n",
    "        batch_size=64,  # 128\n",
    "        dataset=\"celeba_hq\",\n",
    "    ):\n",
    "        super(VQVAE_Trainer, self).__init__()\n",
    "        self.model = VQVAE(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            num_hiddens=num_hiddens,\n",
    "            num_downsampling_layers=num_downsampling_layers,\n",
    "            num_residual_layers=num_residual_layers,\n",
    "            num_residual_hiddens=num_residual_hiddens,\n",
    "            embedding_dim=embedding_dim,\n",
    "            num_embeddings=num_embeddings,\n",
    "            use_ema=use_ema,\n",
    "            decay=decay,\n",
    "            epsilon=epsilon,\n",
    "        )\n",
    "\n",
    "        self.beta = beta\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        out = self.model(x)\n",
    "        recon_error = F.mse_loss(out[\"x_recon\"], x)\n",
    "\n",
    "        loss = recon_error + self.beta * out[\"commitment_loss\"]\n",
    "\n",
    "        if out[\"dictionary_loss\"] is not None:\n",
    "            loss += out[\"dictionary_loss\"]\n",
    "            self.log(\"train_dictionary_loss\", out[\"dictionary_loss\"])\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_recon_error\", recon_error)\n",
    "        self.log(\"train_commitment_loss\", out[\"commitment_loss\"])\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        out = self.model(x)\n",
    "\n",
    "        recon_error = F.mse_loss(out[\"x_recon\"], x)\n",
    "\n",
    "        loss = recon_error + self.beta * out[\"commitment_loss\"]\n",
    "\n",
    "        if out[\"dictionary_loss\"] is not None:\n",
    "            loss += out[\"dictionary_loss\"]\n",
    "            self.log(\"val_dictionary_loss\", out[\"dictionary_loss\"])\n",
    "\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_recon_error\", recon_error)\n",
    "        self.log(\"val_commitment_loss\", out[\"commitment_loss\"])\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            if self.global_step == 0 and batch_idx == 0:\n",
    "                self.logger.experiment.log(\n",
    "                    {\n",
    "                        \"original\": wandb.Image(\n",
    "                            torchvision.utils.make_grid(x[:64], nrow=8),\n",
    "                            caption=\"Real Image\",\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            self.logger.experiment.log(\n",
    "                {\n",
    "                    \"reconstructed\": wandb.Image(\n",
    "                        torchvision.utils.make_grid(out[\"x_recon\"][:64], nrow=8),\n",
    "                        caption=f\"Step {self.global_step}\",\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "    def on_test_start(self):\n",
    "        self.fid = FrechetInceptionDistance(self.hparams.fid_features).cpu()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        out = self.model(x)\n",
    "\n",
    "        # Resize to 299x299\n",
    "        x = F.interpolate(x, size=299)\n",
    "        x_hat = F.interpolate(out[\"x_recon\"], size=299)\n",
    "\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "            x_hat = x_hat.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # Convert to uint8\n",
    "        x = (x * 255).to(torch.uint8).cpu()\n",
    "        x_hat = (x_hat * 255).to(torch.uint8).cpu()\n",
    "\n",
    "        # Compute FID\n",
    "        self.fid.update(x, real=True)\n",
    "        self.fid.update(x_hat, real=False)\n",
    "\n",
    "        fid_score = self.fid.compute()\n",
    "        self.log(\"fid_score\", fid_score)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            amsgrad=True,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.hparams.dataset == \"mnist\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    (\n",
    "                        torchvision.transforms.Grayscale()\n",
    "                        if self.hparams.in_channels == 1\n",
    "                        else torchvision.transforms.Lambda(lambda x: x)\n",
    "                    ),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.MNIST(\n",
    "                root=\"data/mnist\", train=True, transform=transform, download=True\n",
    "            )\n",
    "\n",
    "        elif self.hparams.dataset == \"cifar10\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.CIFAR10(\n",
    "                root=\"data/cifar10\", train=True, transform=transform, download=True\n",
    "            )\n",
    "\n",
    "        elif self.hparams.dataset == \"celeba_hq\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.ImageFolder(\n",
    "                \"data/celeba_hq/train\", transform=transform\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset: {self.hparams.dataset}\")\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        if self.hparams.dataset == \"mnist\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.MNIST(\n",
    "                root=\"data/mnist\", train=False, transform=transform, download=True\n",
    "            )\n",
    "\n",
    "        elif self.hparams.dataset == \"cifar10\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.CIFAR10(\n",
    "                root=\"data/cifar10\", train=False, transform=transform, download=True\n",
    "            )\n",
    "\n",
    "        elif self.hparams.dataset == \"celeba_hq\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.ImageFolder(\n",
    "                \"data/celeba_hq/val\", transform=transform\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset: {self.hparams.dataset}\")\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        if self.hparams.dataset == \"mnist\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.MNIST(\n",
    "                root=\"data/mnist\", train=False, transform=transform, download=True\n",
    "            )\n",
    "            # Return first 1/4\n",
    "            dataset = torch.utils.data.Subset(dataset, range(len(dataset) // 16))\n",
    "\n",
    "        elif self.hparams.dataset == \"cifar10\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.CIFAR10(\n",
    "                root=\"data/cifar10\", train=False, transform=transform, download=True\n",
    "            )\n",
    "            # Return first 1/4\n",
    "            dataset = torch.utils.data.Subset(dataset, range(len(dataset) // 16))\n",
    "\n",
    "        elif self.hparams.dataset == \"celeba_hq\":\n",
    "            transform = torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize(self.hparams.sample_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            dataset = torchvision.datasets.ImageFolder(\n",
    "                \"data/celeba_hq/val\", transform=transform\n",
    "            )\n",
    "            # Return first 1/4\n",
    "            dataset = torch.utils.data.Subset(dataset, range(len(dataset) // 4))\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset: {self.hparams.dataset}\")\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VQVAE(\n",
       "  (encoder): Encoder(\n",
       "    (conv): Sequential(\n",
       "      (down0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (relu0): ReLU()\n",
       "      (down1): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (relu1): ReLU()\n",
       "      (final_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (residual_stack): ResidualStack(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_vq_conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (vq): VectorQuantizer(\n",
       "    (N_i_ts): SonnetExponentialMovingAverage()\n",
       "    (m_i_ts): SonnetExponentialMovingAverage()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (conv): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (residual_stack): ResidualStack(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (upconv): Sequential(\n",
       "      (up0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (relu0): ReLU()\n",
       "      (up1): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load from checkpoint\n",
    "vqvae = VQVAE_Trainer.load_from_checkpoint(\"vqvae/logs/vq-vae/mnist-32/checkpoints/epoch=10-step=10000.ckpt\")\n",
    "vqvae = vqvae.model.to(\"mps\")\n",
    "vqvae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diffusers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiser = diffusers.DDIMScheduler(\n",
    "    num_train_timesteps=1_000,\n",
    "    rescale_betas_zero_snr=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,024,900 parameters\n"
     ]
    }
   ],
   "source": [
    "model = diffusers.UNet2DModel(\n",
    "    sample_size=(8, 8),\n",
    "    in_channels=4,\n",
    "    out_channels=4,\n",
    "    down_block_types=(\"AttnDownBlock2D\"),\n",
    "    up_block_types=(\"AttnUpBlock2D\"),\n",
    "    block_out_channels=(64),\n",
    "    layers_per_block=2,\n",
    "\n",
    ").to(\"mps\")\n",
    "print(f\"{model.num_parameters():,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0912976ede4bc2b1d4e6d5f807fd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def generate():\n",
    "    # Plot some images\n",
    "    model.eval()\n",
    "    pipeline = diffusers.DDIMPipeline(model, noiser)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        imgs = pipeline(\n",
    "            batch_size=8, num_inference_steps=50, output_type=\"np\", eta=1\n",
    "        ).images\n",
    "\n",
    "    # Decode the images\n",
    "    imgs = torch.as_tensor(imgs).permute(0, 3, 1, 2).to(\"mps\")\n",
    "    imgs = vqvae.decoder(imgs).squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axs = plt.subplots(1, 8, figsize=(16, 4))\n",
    "\n",
    "    for i in range(8):\n",
    "        axs[i].imshow(imgs[i], cmap=\"gray\")\n",
    "        axs[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    model.train()\n",
    "\n",
    "\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.load(\"projects/custom/vq-vae/z_embed/train_z_embed.pt\"),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    torch.load(\"projects/custom/vq-vae/z_embed/val_z_embed.pt\"),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/y4w577ts6qb9hpql_4lr_km40000gn/T/ipykernel_84017/446596784.py:2: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  with tqdm.tnrange(100, desc=\"epochs\") as epochs:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37267c059b5140159e418cbc9b0f5ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 938/938 [03:45<00:00,  4.16it/s]\n",
      "train:  73%|███████▎  | 685/938 [02:58<01:05,  3.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 18\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m epochs\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# ema.update()\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/repos/ml-playground/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/repos/ml-playground/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Coding/repos/ml-playground/venv/lib/python3.10/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Coding/repos/ml-playground/venv/lib/python3.10/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/repos/ml-playground/venv/lib/python3.10/site-packages/torch/optim/adam.py:441\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 441\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "with tqdm.tnrange(100, desc=\"epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        for i, (x, _) in enumerate(tqdm.tqdm(train_loader, desc=\"train\", leave=True)):\n",
    "            x = x.to(\"mps\")\n",
    "            \n",
    "            noise = torch.randn_like(x, device=\"mps\")\n",
    "            timestep = torch.randint(0, 1000, (x.shape[0],), device=\"mps\")\n",
    "\n",
    "            noisy_image = noiser.add_noise(x, noise, timestep)\n",
    "\n",
    "            model_output = model(noisy_image, timestep).sample\n",
    "\n",
    "            loss = torch.nn.functional.mse_loss(model_output, x)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            epochs.set_postfix(loss=loss.item())\n",
    "            # ema.update()\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
