{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 60000 samples\n"
     ]
    }
   ],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((32, 32)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.QMNIST('data', train=True, download=True, transform=transforms)\n",
    "# test_dataset = torchvision.datasets.QMNIST('data', train=False, download=True, transform=transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Training with {len(train_dataset)} samples\")\n",
    "# print(f\"Testing with {len(test_dataset)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, d, latent_dim):\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 128 // d, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128 // d, 256 // d, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256 // d, 512 // d, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512 // d,latent_dim, 4, 1, 0),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        self.mu = nn.Linear(latent_dim, latent_dim)\n",
    "        self.logvar = nn.Linear(latent_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        mu = self.mu(x)\n",
    "        logvar = self.logvar(x)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def kl_divergence(self, mu, logvar):\n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    def sample(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "class VariationalDecoder(nn.Module):\n",
    "    def __init__(self, d, latent_dim):\n",
    "        super(VariationalDecoder, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 1024 // d),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (1024 // d, 1, 1)),\n",
    "            nn.ConvTranspose2d(1024 // d, 512 // d, 4, 1, 0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512 // d, 256 // d, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256 // d, 128 // d, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128 // d, 1, 4, 2, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 128 // d, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128 // d, 256 // d, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256 // d, 512 // d, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 1),            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def gradient_penalty(self, real, fake):\n",
    "        alpha = torch.rand(real.size(0), 1, 1, 1, device=real.device)\n",
    "        interpolates = alpha * real + (1 - alpha) * fake\n",
    "        d_interpolates = self(interpolates)\n",
    "        gradients = torch.autograd.grad(outputs=d_interpolates, inputs=interpolates,\n",
    "                                        grad_outputs=torch.ones(d_interpolates.size(), device=real.device),\n",
    "                                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        return ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = VariationalEncoder(8, 32).to(device)\n",
    "decoder = VariationalDecoder(8, 32).to(device)\n",
    "discriminator = Discriminator(8).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAEGAN\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-4)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=1e-4)\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0it [00:01, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m loss_fake_for_encoder \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(fake_preds, torch\u001b[38;5;241m.\u001b[39mzeros_like(fake_preds))\n\u001b[1;32m     32\u001b[0m decoder_loss \u001b[38;5;241m=\u001b[39m loss_fake_for_encoder \u001b[38;5;241m-\u001b[39m loss_gan\n\u001b[0;32m---> 33\u001b[0m \u001b[43mdecoder_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m decoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Discriminator loss: BCE with logits + Gradient penalty\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/repos/ml-zoo/venv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/repos/ml-zoo/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    with tqdm.tqdm(enumerate(train_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, (x, _) in pbar:\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # Forward pass through encoder and decoder\n",
    "            mu, logvar = encoder(x)\n",
    "            z = encoder.sample(mu, logvar)\n",
    "            x_tilde = decoder(z)\n",
    "            \n",
    "            # Discriminator outputs\n",
    "            real_preds = discriminator(x)\n",
    "            fake_preds = discriminator(x_tilde.detach())  # Detach to avoid backpropagation through decoder\n",
    "            \n",
    "            # Encoder loss: KL Divergence + Discriminator likelihood\n",
    "            encoder_optimizer.zero_grad()\n",
    "            loss_prior = encoder.kl_divergence(mu, logvar)  # Your encoder should have this method\n",
    "            loss_real = F.binary_cross_entropy_with_logits(real_preds, torch.ones_like(real_preds))\n",
    "            loss_fake_for_encoder = F.binary_cross_entropy_with_logits(fake_preds, torch.zeros_like(fake_preds))\n",
    "            encoder_loss = loss_prior + (loss_real + loss_fake_for_encoder)\n",
    "            encoder_loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            \n",
    "            # Decoder loss: Discriminator likelihood - GAN loss\n",
    "            decoder_optimizer.zero_grad()\n",
    "            # Re-sample z to avoid using the same values as in encoder loss backprop\n",
    "            z = encoder.sample(mu, logvar)\n",
    "            x_tilde = decoder(z)\n",
    "            fake_preds_for_decoder = discriminator(x_tilde)\n",
    "            loss_gan = -fake_preds_for_decoder.mean()  # Minimize -E[log(D(G(z)))]\n",
    "            loss_fake_for_encoder = F.binary_cross_entropy_with_logits(fake_preds, torch.zeros_like(fake_preds))\n",
    "            decoder_loss = loss_fake_for_encoder - loss_gan\n",
    "            decoder_loss.backward()\n",
    "            decoder_optimizer.step()\n",
    "            \n",
    "            # Discriminator loss: BCE with logits + Gradient penalty\n",
    "            discriminator_optimizer.zero_grad()\n",
    "            # Compute the loss for real and fake images\n",
    "            loss_real = F.binary_cross_entropy_with_logits(real_preds, torch.ones_like(real_preds))\n",
    "            loss_fake_for_discriminator = F.binary_cross_entropy_with_logits(fake_preds_for_decoder, torch.zeros_like(fake_preds_for_decoder))\n",
    "            loss_discriminator = loss_real + loss_fake_for_discriminator\n",
    "            # Calculate gradient penalty\n",
    "            loss_gradient_penalty = discriminator.gradient_penalty(x, x_tilde.detach())  # Your discriminator should have this method\n",
    "            discriminator_loss = loss_discriminator + loss_gradient_penalty * 10  # Adjust lambda for gradient penalty if necessary\n",
    "            discriminator_loss.backward()\n",
    "            discriminator_optimizer.step()\n",
    "            \n",
    "            # Progress bar update\n",
    "            pbar.set_postfix_str(f\"Encoder Loss: {encoder_loss.item()}, Decoder Loss: {decoder_loss.item()}, Discriminator Loss: {discriminator_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
