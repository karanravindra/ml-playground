{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import tqdm as tqdm\n",
    "import lightning.pytorch as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "import diffusers\n",
    "\n",
    "\n",
    "class DDPM(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr=1e-3,\n",
    "        batch_size=64,\n",
    "        w_decay=4e-5,\n",
    "    ):\n",
    "        super(DDPM, self).__init__()\n",
    "        self.model = diffusers.UNet2DModel(\n",
    "            sample_size=(128, 128),\n",
    "            in_channels=3,\n",
    "            out_channels=3,\n",
    "            down_block_types=(\n",
    "                \"DownBlock2D\",\n",
    "                \"DownBlock2D\",\n",
    "                \"AttnDownBlock2D\",\n",
    "                \"AttnDownBlock2D\",\n",
    "            ),  # \"DownBlock2D\", \"AttnDownBlock2D\",\n",
    "            up_block_types=(\n",
    "                \"AttnUpBlock2D\",\n",
    "                \"AttnUpBlock2D\",\n",
    "                \"UpBlock2D\",\n",
    "                \"UpBlock2D\",\n",
    "            ),  # \"UpBlock2D\", \"AttnUpBlock2D\",\n",
    "            block_out_channels=(64, 128, 256, 256),\n",
    "            layers_per_block=2,\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr=lr, weight_decay=w_decay)\n",
    "        self.scheduler = diffusers.DDIMScheduler(\n",
    "            num_train_timesteps=4000,\n",
    "            rescale_betas_zero_snr=True,\n",
    "        )\n",
    "        self.fid = FrechetInceptionDistance(feature=2048)\n",
    "        self.batch_size = batch_size\n",
    "        self.criterion = F.mse_loss\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert True, \"Forward not implemented\"\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        t = torch.randint(\n",
    "            0, self.scheduler.num_train_timesteps, (x.size(0),), device=x.device\n",
    "        )\n",
    "        noise = torch.randn_like(x, device=x.device)\n",
    "        x_noisy = self.scheduler.add_noise(x, noise, t)\n",
    "\n",
    "        # Forward Pass\n",
    "        x_pred = self.model(x_noisy, t).sample\n",
    "        loss = self.criterion(x_pred, noise)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        imgs_eta0 = self.generate(num_images=8, num_inference_steps=50, eta=0)\n",
    "        imgs_eta05 = self.generate(num_images=8, num_inference_steps=50, eta=0.5)\n",
    "        imgs_eta1 = self.generate(num_images=8, num_inference_steps=50, eta=1)\n",
    "\n",
    "        # Log images\n",
    "        self.logger.experiment.log(\n",
    "            {\n",
    "                \"eta: 0\": [wandb.Image(img) for img in imgs_eta0],\n",
    "                \"eta: 0.5\": [wandb.Image(img) for img in imgs_eta05],\n",
    "                \"eta: 1\": [wandb.Image(img) for img in imgs_eta1],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Log FID\n",
    "        # Upscale images to 299x299\n",
    "        imgs_eta0 = F.interpolate(\n",
    "            imgs_eta0, size=(299, 299), mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        # imgs_eta05 = F.interpolate(\n",
    "        #     imgs_eta05, size=(299, 299), mode=\"bilinear\", align_corners=False\n",
    "        # )\n",
    "        imgs_eta1 = F.interpolate(\n",
    "            imgs_eta1, size=(299, 299), mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        x = F.interpolate(x, size=(299, 299), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        # Convert to uint8\n",
    "        imgs_eta0 = (imgs_eta0 * 255).to(torch.uint8).to(\"cuda\")\n",
    "        # imgs_eta05 = (imgs_eta05 * 255).to(torch.uint8).to(\"cuda\")\n",
    "        imgs_eta1 = (imgs_eta1 * 255).to(torch.uint8).to(\"cuda\")\n",
    "        x = (x * 255).to(torch.uint8).to(\"cuda\")\n",
    "\n",
    "        # Calculate FID\n",
    "        # eta 0\n",
    "        self.fid.update(x, True)\n",
    "        self.fid.update(imgs_eta0, False)\n",
    "        self.log(\"fid eta: 0\", self.fid.compute())\n",
    "\n",
    "        # # eta 0.5\n",
    "        # self.fid.update(x, True)\n",
    "        # self.fid.update(imgs_eta05, False)\n",
    "        # self.log(\"fid eta: 0.5\", self.fid.compute())\n",
    "\n",
    "        # eta 1\n",
    "        self.fid.update(x, True)\n",
    "        self.fid.update(imgs_eta1, False)\n",
    "        self.log(\"fid eta: 1\", self.fid.compute())\n",
    "\n",
    "    def generate(self, num_images=8, num_inference_steps=50, eta=0.0):\n",
    "        # Plot some images\n",
    "        self.model.eval()\n",
    "        pipeline = diffusers.DDIMPipeline(self.model, self.scheduler).to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            imgs = pipeline(\n",
    "                batch_size=num_images,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                output_type=\"np\",\n",
    "                eta=eta,\n",
    "            ).images\n",
    "\n",
    "        # convert to torch tensor\n",
    "        imgs = torch.tensor(imgs)\n",
    "        imgs = imgs.permute(0, 3, 1, 2)\n",
    "\n",
    "        return imgs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.ImageFolder(\n",
    "                \"data/celeba_hq/train\",\n",
    "                transform=torchvision.transforms.Compose(\n",
    "                    [\n",
    "                        torchvision.transforms.Resize(128),\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.ImageFolder(\n",
    "                \"data/celeba_hq/val\",\n",
    "                transform=torchvision.transforms.Compose(\n",
    "                    [\n",
    "                        torchvision.transforms.Resize(128),\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "\n",
    "def main():\n",
    "    logger = WandbLogger(\n",
    "        name=\"128x conv2d ddim\", project=\"diffusion\", log_model=\"all\", save_code=True\n",
    "    )\n",
    "    model = DDPM()\n",
    "    logger.watch(model, log=\"all\", log_freq=10, log_graph=True)\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger,\n",
    "        check_val_every_n_epoch=1,\n",
    "        limit_val_batches=1,\n",
    "        log_every_n_steps=1,\n",
    "        accumulate_grad_batches=4,\n",
    "        max_steps=500_000,\n",
    "        precision=\"bf16-mixed\",\n",
    "    )\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
