{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Review: Cifar10 with PyTorch\n",
    "![image](output.png)\n",
    "## Introduction\n",
    "This notebook is a review of the architecture used in the PyTorch tutorial for the CIFAR10 dataset. This is the complete code for the tutorial, with some minor modifications to make it more readable and to modify the architectures for this dataset. To find the practice notebook, please visit the following link: [Practice Notebook](). \n",
    "\n",
    "### Pre-requisites\n",
    "This notebook assumes that you have a basic understanding of neural networks and PyTorch. If you are new to PyTorch, please visit the following link to get started: [PyTorch Tutorials](https://pytorch.org/tutorials/). Please complete the [MNIST tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html) before starting this tutorial.\n",
    "\n",
    "### Dataset\n",
    "The CIFAR10 dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, and other similar vehicles. \"Truck\" includes only big trucks. The test batch contains 1,000 randomly selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5,000 images from each class. While you may realize that this doesn't sound like it's useful for real-world applications, it's a good dataset to start with and learn the basics of deep learning since it's small and easy to work with. \n",
    "\n",
    "**Classes**:\n",
    "- airplane\n",
    "- automobile\n",
    "- bird\n",
    "- cat\n",
    "- deer\n",
    "- dog\n",
    "- frog\n",
    "- horse\n",
    "- ship\n",
    "- truck\n",
    "- [CIFAR10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "- [CIFAR10 Dataset PyTorch](https://pytorch.org/vision/stable/datasets.html#cifar)\n",
    "\n",
    "**Critcism**:\n",
    "The CIFAR10 dataset is a very small dataset and is not representative of real-world data. It is used for educational purposes and to learn the basics of deep learning. Intersting read: [Once Upon a Time in CIFAR-10](https://franky07724-57962.medium.com/once-upon-a-time-in-cifar-10-c26bb056b4ce#:~:text=However%2C%20the%20quality%20of%20CIFAR,10%20contains%200.54%25%20label%20errors.)\n",
    "\n",
    "\n",
    "**Note**: \n",
    "There is also a CIFAR100 dataset, which has 100 classes. For the extra challenge, you can try working with the CIFAR100 dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code setup\n",
    "Let's start by importing the necessary libraries and setting up the code for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import tqdm as tqdm\n",
    "from lightning import pytorch as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to load the CIFAR10 dataset using the `torchvision` library. The dataset is divided into training and testing sets, and each set contains images and their corresponding labels (0-9). The images are also normalized to have a mean of 0.5 and a standard deviation of 0.5. This normalization helps the neural network since it allows the weights to be updated more evenly during training.\n",
    "\n",
    "The batch size is set to 64, though you can change it to a different value if you like. The batch size determines how many images are processed at once during training. A larger batch size can speed up training but requires more memory. A smaller batch size can slow down training but may lead to better generalization.\n",
    "\n",
    "Finally, we create a DataLoader for the training and testing sets. The DataLoader is used to load the data in batches during training and testing. It also shuffles the data during training to ensure that the model learns from different samples in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Classifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        batch_size: int,\n",
    "        lr: float,\n",
    "        momentum: float,\n",
    "        w_decay: float,\n",
    "        T_max: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.w_decay = w_decay\n",
    "        self.T_max = T_max\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        train_acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"train_acc\", train_acc)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        \n",
    "        val_acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_acc\", val_acc)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        \n",
    "        test_acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=self.lr,\n",
    "            momentum=self.momentum,\n",
    "            weight_decay=self.w_decay,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=self.T_max\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            tv.datasets.CIFAR10(\n",
    "                root=\"./data\",\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=tv.transforms.ToTensor(),\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            tv.datasets.CIFAR10(\n",
    "                root=\"./data\",\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=tv.transforms.ToTensor(),\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            tv.datasets.CIFAR10(\n",
    "                root=\"./data\",\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=tv.transforms.ToTensor(),\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"w_decay\": 5e-4,\n",
    "    \"T_max\": 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>projects/blog/cifar10/logs/wandb/run-20240428_214109-sey1hmxb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karanravindra/cifar10/runs/sey1hmxb/workspace' target=\"_blank\">single-layer-perceptron</a></strong> to <a href='https://wandb.ai/karanravindra/cifar10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karanravindra/cifar10' target=\"_blank\">https://wandb.ai/karanravindra/cifar10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karanravindra/cifar10/runs/sey1hmxb/workspace' target=\"_blank\">https://wandb.ai/karanravindra/cifar10/runs/sey1hmxb/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:44: attribute 'model' removed from hparams because it cannot be pickled\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | Sequential       | 30.7 K\n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "30.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "30.7 K    Total params\n",
      "0.123     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3732999861240387     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.8373949527740479     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3732999861240387    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.8373949527740479    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90186af02bc247d4840ef13ffbf56242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.275 MB of 0.275 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▅▃▄▅▅▄▅▃▃▆▅▁▃▃▆▃▅▃▇▁▂▄█▂▃▇▅█▆▂▆▄▅▅▆▅▂▂▅▂</td></tr><tr><td>train_loss</td><td>▄▅▄▅▃█▆▄▅▅▃▄▇█▂▄▄▄▂▅▅▅▃▆▅▂▄▁▃▄▆▅▃▄▂▅▇▆▂▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▅▁▅▂▆▄▆▅▇▆▇▆▅▆▇▆▄█▄█▆▆▆▆▄▆▇▇▇▇</td></tr><tr><td>val_loss</td><td>▃█▄▆▂▄▂▄▁▄▃▃▄▃▁▃▆▁▅▁▄▃▃▃▅▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>test_acc</td><td>0.3733</td></tr><tr><td>test_loss</td><td>1.83739</td></tr><tr><td>train_acc</td><td>0.48438</td></tr><tr><td>train_loss</td><td>1.46853</td></tr><tr><td>trainer/global_step</td><td>12053</td></tr><tr><td>val_acc</td><td>0.35938</td></tr><tr><td>val_loss</td><td>1.9315</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">single-layer-perceptron</strong> at: <a href='https://wandb.ai/karanravindra/cifar10/runs/sey1hmxb/workspace' target=\"_blank\">https://wandb.ai/karanravindra/cifar10/runs/sey1hmxb/workspace</a><br/>Synced 2 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path projects/blog/cifar10/logs/wandb/ wasn't writable, using system temp directory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/tmp/wandb/run-20240428_214109-sey1hmxb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a simple model\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32 * 32 * 3, 10),\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = WandbLogger(\n",
    "        name=\"single-layer-perceptron\",\n",
    "        project=\"cifar10\",\n",
    "        save_dir=\"projects/blog/cifar10/logs\",\n",
    "        log_model=True,\n",
    "    )\n",
    "    logger.watch(model, log=\"all\")\n",
    "\n",
    "    cifarTrainer = CIFAR10Classifier(model, **hyperparameters)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=20,\n",
    "        logger=logger,\n",
    "        val_check_interval=0.5,\n",
    "        limit_val_batches=0.25,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(cifarTrainer)\n",
    "    trainer.test(cifarTrainer)\n",
    "\n",
    "    logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple model\n",
    "model = torch.nn.Sequential(\n",
    "    # Flatten Layer\n",
    "    torch.nn.Flatten(),\n",
    "    # Fully Connected Layer\n",
    "    torch.nn.Linear(32 * 32 * 3, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 10),\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = WandbLogger(\n",
    "        name=\"multi-layer-perceptron\",\n",
    "        project=\"cifar10\",\n",
    "        save_dir=\"projects/blog/cifar10/logs\",\n",
    "        log_model=True,\n",
    "    )\n",
    "    logger.watch(model, log=\"all\")\n",
    "\n",
    "    cifarTrainer = CIFAR10Classifier(model, **hyperparameters)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=20,\n",
    "        logger=logger,\n",
    "        val_check_interval=0.5,\n",
    "        limit_val_batches=0.25,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(cifarTrainer)\n",
    "    trainer.test(cifarTrainer)\n",
    "\n",
    "    logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lenet-5](https://www.datasciencecentral.com/wp-content/uploads/2021/10/1lvvWF48t7cyRWqct13eU0w.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    # First convolutional layer\n",
    "    nn.Conv2d(3, 6, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    # Second convolutional layer\n",
    "    nn.Conv2d(6, 16, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    # Flatten layer\n",
    "    nn.Flatten(),\n",
    "    # Fully connected layers\n",
    "    nn.Linear(16 * 5 * 5, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(84, 10),\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = WandbLogger(\n",
    "        name=\"lenet-5\",\n",
    "        project=\"cifar10\",\n",
    "        save_dir=\"projects/blog/cifar10/logs\",\n",
    "        log_model=True,\n",
    "    )\n",
    "    logger.watch(model, log=\"all\")\n",
    "\n",
    "    cifarTrainer = CIFAR10Classifier(model, **hyperparameters)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=20,\n",
    "        logger=logger,\n",
    "        val_check_interval=0.5,\n",
    "        limit_val_batches=0.25,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(cifarTrainer)\n",
    "    trainer.test(cifarTrainer)\n",
    "\n",
    "    logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Dropout (Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b04f3331a204028a7c0d8807356a5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.550 MB of 0.550 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆█████</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▃▂█▂▇▆▂▆▃▁▄▅▆▃▅▅▇▄▂▅▄█▄▁▄▅▇▅▄▇▅▆▄█▅▆▄▇▅▃</td></tr><tr><td>train_loss</td><td>▆▅▁▆▆▅▄▅▅▇▆▇▄█▇▅▄▅▇▇▃▄▇▇▅▇▄▅▆▆▅▅▅▄█▆▅▅▇█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>█▅▁▅▃▂▂▇</td></tr><tr><td>val_loss</td><td>▁▄▆█▅▆█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>test_acc</td><td>0.1</td></tr><tr><td>test_loss</td><td>2.30862</td></tr><tr><td>train_acc</td><td>0.0625</td></tr><tr><td>train_loss</td><td>2.32275</td></tr><tr><td>trainer/global_step</td><td>3518</td></tr><tr><td>val_acc</td><td>0.10617</td></tr><tr><td>val_loss</td><td>2.30556</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lenet-5 | dropout</strong> at: <a href='https://wandb.ai/karanravindra/cifar10/runs/n9fkocaj/workspace' target=\"_blank\">https://wandb.ai/karanravindra/cifar10/runs/n9fkocaj/workspace</a><br/>Synced 7 W&B file(s), 1 media file(s), 1 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>projects/blog/cifar10/logs/wandb/run-20240428_213625-n9fkocaj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    # First convolutional layer\n",
    "    nn.Conv2d(3, 6, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    # Second convolutional layer\n",
    "    nn.Conv2d(6, 16, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    # Flatten layer\n",
    "    nn.Flatten(),\n",
    "    # Dropout Layer\n",
    "    nn.Dropout(0.5),\n",
    "    # Fully connected layers\n",
    "    nn.Linear(16 * 5 * 5, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(84, 10),\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = WandbLogger(\n",
    "        name=\"lenet-5 | dropout\",\n",
    "        project=\"cifar10\",\n",
    "        save_dir=\"projects/blog/cifar10/logs\",\n",
    "        log_model=True,\n",
    "    )\n",
    "    logger.watch(model, log=\"all\")\n",
    "\n",
    "    cifarTrainer = CIFAR10Classifier(model, **hyperparameters)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=20,\n",
    "        logger=logger,\n",
    "        val_check_interval=0.5,\n",
    "        limit_val_batches=0.25,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(cifarTrainer)\n",
    "    trainer.test(cifarTrainer)\n",
    "\n",
    "    logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Modern CNNs and better Training Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    # First convolutional layer\n",
    "    nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Second convolutional layer\n",
    "    nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Third convolutional layer\n",
    "    nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Flatten layer\n",
    "    nn.Flatten(),\n",
    "\n",
    "    # Fully connected layers\n",
    "    nn.Linear(128 * 4 * 4, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 10)\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = WandbLogger(\n",
    "        name=\"cnn\",\n",
    "        project=\"cifar10\",\n",
    "        save_dir=\"projects/blog/cifar10/logs\",\n",
    "        log_model=True,\n",
    "    )\n",
    "    logger.watch(model, log=\"all\")\n",
    "\n",
    "    cifarTrainer = CIFAR10Classifier(model, **hyperparameters)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=20,\n",
    "        logger=logger,\n",
    "        val_check_interval=0.5,\n",
    "        limit_val_batches=0.25,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(cifarTrainer)\n",
    "    trainer.test(cifarTrainer)\n",
    "\n",
    "    logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Normalization + Dropout (Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    # First convolutional layer\n",
    "    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Second convolutional layer\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Third convolutional layer\n",
    "    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Flatten layer\n",
    "    nn.Flatten(),\n",
    "    # Dropout Layer\n",
    "    nn.Dropout(0.5),\n",
    "    # Fully connected layers\n",
    "    nn.Linear(in_features=128 * 4 * 4, out_features=512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=512, out_features=10)\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = WandbLogger(\n",
    "        name=\"cnn | batchnorm\",\n",
    "        project=\"cifar10\",\n",
    "        save_dir=\"projects/blog/cifar10/logs\",\n",
    "        log_model=True,\n",
    "    )\n",
    "    logger.watch(model, log=\"all\")\n",
    "    cifarTrainer = CIFAR10Classifier(model, **hyperparameters)\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=20,\n",
    "        logger=logger,\n",
    "        val_check_interval=0.5,\n",
    "        limit_val_batches=0.25,\n",
    "    )\n",
    "    trainer.fit(cifarTrainer)\n",
    "    trainer.test(cifarTrainer)\n",
    "\n",
    "    logger.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vgg-16](https://miro.medium.com/v2/resize:fit:1400/1*NNifzsJ7tD2kAfBXt3AzEg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers([64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    \n",
    "model = VGG()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = WandbLogger(\n",
    "        name=\"vgg-16\",\n",
    "        project=\"cifar10\",\n",
    "        save_dir=\"projects/blog/cifar10/logs\",\n",
    "        log_model=True,\n",
    "    )\n",
    "    logger.watch(model, log=\"all\")\n",
    "\n",
    "    cifarTrainer = CIFAR10Classifier(model, **hyperparameters)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=20,\n",
    "        logger=logger,\n",
    "        val_check_interval=0.5,\n",
    "        limit_val_batches=0.25,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(cifarTrainer)\n",
    "    trainer.test(cifarTrainer)\n",
    "\n",
    "    logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(Bottleneck, [3, 4, 6, 3]) # ResNet-50\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = WandbLogger(\n",
    "        name=\"resnet-50\",\n",
    "        project=\"cifar10\",\n",
    "        save_dir=\"projects/blog/cifar10/logs\",\n",
    "        log_model=True,\n",
    "    )\n",
    "    logger.watch(model, log=\"all\")\n",
    "\n",
    "    cifarTrainer = CIFAR10Classifier(model, **hyperparameters)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=20,\n",
    "        logger=logger,\n",
    "        val_check_interval=0.5,\n",
    "        limit_val_batches=0.25,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(cifarTrainer)\n",
    "    trainer.test(cifarTrainer)\n",
    "\n",
    "    logger.experiment.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
