{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and format Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('blog/3-names/data/names.txt') as f:\n",
    "    names = f.read().split()\n",
    "\n",
    "random.shuffle(names)\n",
    "\n",
    "train_test = (0.8, 0.2)\n",
    "\n",
    "train_names = names[:int(len(names) * train_test[0])]\n",
    "test_names = names[int(len(names) * train_test[0]):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = ['<s>', '</s>', '<unk>', '<pad>']\n",
    "vocab = special_tokens + sorted(set(''.join(names)))\n",
    "char2idx = {c: i for i, c in enumerate(vocab)}\n",
    "idx2char = {i: c for i, c in enumerate(vocab)}\n",
    "\n",
    "# encode names\n",
    "train_names_encoded = [[char2idx[c] for c in name] for name in train_names]\n",
    "test_names_encoded = [[char2idx[c] for c in name] for name in test_names]\n",
    "\n",
    "# add start and end tokens\n",
    "train_names_encoded = [[char2idx['<s>']] + name + [char2idx['</s>']] for name in train_names_encoded]\n",
    "test_names_encoded = [[char2idx['<s>']] + name + [char2idx['</s>']] for name in test_names_encoded]\n",
    "\n",
    "# Flatten dataset\n",
    "train_names_encoded = list(itertools.chain(*train_names_encoded))\n",
    "test_names_encoded = list(itertools.chain(*test_names_encoded))\n",
    "\n",
    "print('Vocab size:', len(vocab))\n",
    "print('Vocabulary:', vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "train_encoded_corpus = torch.tensor(train_names_encoded).flatten().to(device)\n",
    "test_encoded_corpus = torch.tensor(test_names_encoded).flatten().to(device)\n",
    "\n",
    "def encode(text: str) -> torch.Tensor:\n",
    "    return torch.tensor([char2idx[c] for c in text], device=device)\n",
    "\n",
    "def decode(tensor: torch.Tensor) -> str:\n",
    "    return ''.join([idx2char[i] for i in tensor])\n",
    "\n",
    "def encode_batch(batch: list) -> torch.Tensor:\n",
    "    return torch.tensor([encode(text) for text in batch], device=device)\n",
    "\n",
    "def decode_batch(batch: torch.Tensor) -> list:\n",
    "    return [decode(tensor) for tensor in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size: int, seq_len: int, train: bool = True) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    if train:\n",
    "        data = train_encoded_corpus\n",
    "        \n",
    "    else:\n",
    "        data = test_encoded_corpus\n",
    "\n",
    "    idx = torch.randint(0, len(data) - seq_len, (batch_size,))\n",
    "    x = torch.stack([data[i:i+seq_len] for i in idx])\n",
    "    y = torch.stack([data[i+1:i+1+seq_len] for i in idx])\n",
    "    return x, y\n",
    "\n",
    "get_batch(2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model):\n",
    "    x, y = get_batch(256, 64)\n",
    "    \n",
    "    out, _ = model(x)\n",
    "    loss = nn.functional.cross_entropy(out.flatten(0, 1), y.flatten())\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size: int, hidden_size: int, num_layers: int, dropout: float\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, num_layers, dropout=dropout, nonlinearity='relu', batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        if h is None:\n",
    "            h = torch.zeros(self.rnn.num_layers, x.size(0), self.rnn.hidden_size, device=x.device)\n",
    "\n",
    "        x = self.emb(x)\n",
    "        x, h = self.rnn(x, h)\n",
    "        x = self.fc(x)\n",
    "        return x, h\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, max_tokens: int, start_seq: str = '') -> str:\n",
    "        h = None\n",
    "        x = torch.cat([torch.tensor([0], device=device), encode(start_seq)]).long().unsqueeze(0)\n",
    "        out = [xi.item() for xi in x.flatten()]\n",
    "        for _ in range(max_tokens):\n",
    "            x, h = self.forward(x, h)\n",
    "            x = x[:, -1].argmax(-1).unsqueeze(0)\n",
    "            \n",
    "            out.append(x.item())\n",
    "            if x.item() == char2idx[\"</s>\"]:\n",
    "                break\n",
    "        return decode(out).replace('<s>', '').replace('</s>', '')\n",
    "\n",
    "\n",
    "model = RNN(len(vocab), hidden_size=128, num_layers=6, dropout=0).to(device)\n",
    "print(model.generate(128, start_seq='A'))\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "test_loss = 0\n",
    "\n",
    "pbar = tqdm.trange(10_000, desc='Training', unit='step')\n",
    "for step in pbar:\n",
    "    x, y = get_batch(256, 64)\n",
    "    out, _ = model(x)\n",
    "    loss = criterion(out.flatten(0, 1), y.flatten())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    pbar.set_postfix(loss=loss.item(), test_loss=test_loss)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        test_loss = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(model.generate(128, start_seq='').replace('<s>', '').replace('</s>', '').strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size: int, hidden_size: int, num_layers: int, dropout: float\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(\n",
    "            hidden_size, hidden_size, num_layers, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        if h is None:\n",
    "            h = torch.zeros(\n",
    "                self.rnn.num_layers, x.size(0), self.rnn.hidden_size, device=x.device\n",
    "            )\n",
    "\n",
    "        x = self.emb(x)\n",
    "        print(x.shape, h.shape)\n",
    "        x, h = self.rnn(x, h)\n",
    "        x = self.fc(x)\n",
    "        return x, h\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, max_tokens: int, start_seq: str = \"\") -> str:\n",
    "        h = None\n",
    "        x = (\n",
    "            torch.cat([torch.tensor([0], device=device), encode(start_seq)])\n",
    "            .long()\n",
    "            .unsqueeze(0)\n",
    "        )\n",
    "        print(x.shape)\n",
    "        out = [xi.item() for xi in x.flatten()]\n",
    "        for _ in range(max_tokens):\n",
    "            x, h = self.forward(x, h)\n",
    "            x = x.argmax(-1)\n",
    "            x = x[:, -1].unsqueeze(0)\n",
    "            out.append(x.item())\n",
    "            if x.item() == char2idx[\"</s>\"]:\n",
    "                break\n",
    "        return decode(out).replace(\"<s>\", \"\").replace(\"</s>\", \"\")\n",
    "\n",
    "\n",
    "model = LSTM(len(vocab), hidden_size=128, num_layers=8, dropout=0).to(device)\n",
    "print(model.generate(128, start_seq=\"A\"))\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "\n",
    "pbar = tqdm.trange(1_000, desc='Training', unit='step')\n",
    "for step in pbar:\n",
    "    x, y = get_batch(256, 64)\n",
    "    out, _ = model(x)\n",
    "    loss = criterion(out.flatten(0, 1), y.flatten())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    pbar.set_postfix(loss=loss.item(), test_loss=test_loss)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        test_loss = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size: int, hidden_size: int, num_layers: int, dropout: float\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, num_layers, dropout=dropout, nonlinearity='relu', batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        if h is None:\n",
    "            h = torch.zeros(self.rnn.num_layers, x.size(0), self.rnn.hidden_size, device=x.device)\n",
    "\n",
    "        x = self.emb(x)\n",
    "        x, h = self.rnn(x, h)\n",
    "        x = self.fc(x)\n",
    "        return x, h\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, max_tokens: int, start_seq: str = '') -> str:\n",
    "        h = None\n",
    "        x = torch.cat([torch.tensor([0], device=device), encode(start_seq)]).long().unsqueeze(0)\n",
    "        out = [xi.item() for xi in x.flatten()]\n",
    "        for _ in range(max_tokens):\n",
    "            x, h = self.forward(x, h)\n",
    "            x = x.argmax(-1)\n",
    "            x = x[:, -1].unsqueeze(0)\n",
    "            out.append(x.item())\n",
    "            if x.item() == char2idx[\"</s>\"]:\n",
    "                break\n",
    "        return decode(out).replace('<s>', '').replace('</s>', '')\n",
    "\n",
    "\n",
    "model = GRU(len(vocab), hidden_size=128, num_layers=8, dropout=0).to(device)\n",
    "print(model.generate(128, start_seq=''))\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
